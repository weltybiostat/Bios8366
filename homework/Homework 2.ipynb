{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework is due Tuesday, October 23, 2018.\n",
    "\n",
    "Each question is worth 25 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(10011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Suppose $y$ has a binomial distribution with parameters $n$ and $p$, and we are interested in the log-odds value $\\theta = \\log(p/(1-p))$. Our prior for $\\theta$ is that $\\theta \\sim N(\\mu, \\sigma^2)$. It follows that the posterior density of $\\theta$ is given, up to a proportionality constant, by:\n",
    "\n",
    "$$\\pi(\\theta | y) \\propto \\frac{\\exp(y\\theta)}{(1 + exp(\\theta))^n} \\exp\\left[\\frac{-(\\theta - \\mu)^2}{2\\sigma^2}\\right]$$\n",
    "\n",
    "For example, suppose we are interested in learning about the probability that a possibly-biased coin lands heads when tossed. *A priori* we believe that the coin is fair, so we assign $\\theta$ a $N(0,.25)$ prior. We toss the coin $n = 5$ times and obtain $y = 5$ heads.\n",
    "\n",
    "1. Using a normal approximation to the posterior density, compute the probability that the coin is biased toward heads (i.e., that θ is positive).\n",
    "2. Using the prior density as a proposal density, design a rejection algorithm for sampling from the posterior distribution. Using simulated draws from your algorithm, approximate the probability that the coin is biased toward heads.\n",
    "3. Using the prior density as a proposal density, simulate values from the posterior distribution using the SIR algorithm. Approximate the probability that the coin is biased toward heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your anser here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "The goal of this problem is to investigate the role of the proposal distribution in a Metropolis-Hastings algorithm designed to simulate from the posterior distribution of the mixture parameter $\\delta$. \n",
    "\n",
    "1. Simulate 200 realizations from the mixture distribution:\n",
    "    $$y_i \\sim \\delta N(7, 0.5^2) + (1-\\delta) N(10, 0.5^2)$$\n",
    "    with $\\delta = 0.7$. Plot a histogram of these data. \n",
    "2. Implement a random walk M-H algorithm with proposal $\\delta^{\\prime} = \\delta^{(i)} + \\epsilon$ with $\\epsilon \\sim Unif(-1,1)$. \n",
    "3. Reparameterize the problem letting $U = \\log\\left[\\frac{\\delta}{1 - \\delta}\\right]$ and $u^{\\prime} = u^{(i)} + \\epsilon$. Implement a random walk chain in U-space. \n",
    "4. Compare the estimates and convergence behavior of the three algorithms.\n",
    "\n",
    "In part (1), you are asked to simulate data from a distribution with $\\delta$ known. For parts (2)–(3), assume $\\delta$ is unknown with prior $\\delta \\sim Unif( 0,1)$. For parts (2)–(3), provide an appropriate plot and a table summarizing the output of the algorithm. \n",
    "\n",
    "To facilitate comparisons, use the same number of iterations, random seed, starting values, and burn-in period for all implementations of the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Carlin (1992) considers a Bayesian approach to meta-analysis, and includes the following examples of 22 trials of beta-blockers to prevent mortality after myocardial infarction. These data are given below.\n",
    "\n",
    "In one possible random effects model we assume the true baseline mean (on a log-odds scale) $m_i$ in a trial $i$\n",
    "is drawn from some population distribution. Let $r^C_i$ denote number of events in the control group in trial $i$, and $r^T_i$ denote events under active treatment in trial $i$. Our model is:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "r^C_i &\\sim \\text{Binomial}\\left(p^C_i, n^C_i\\right) \\\\\n",
    "r^T_i &\\sim \\text{Binomial}\\left(p^T_i, n^T_i\\right) \\\\\n",
    "\\text{logit}\\left(p^C_i\\right) &= \\mu_i \\\\\n",
    "\\text{logit}\\left(p^T_i\\right) &= \\mu_i + \\delta \\\\\n",
    "\\mu_i &\\sim \\text{Normal}(m, s).\n",
    "\\end{aligned}$$\n",
    "\n",
    "In this case, we want to make inferences about the population effect $m$, and the predictive distribution for the effect $\\delta_{\\text{new}}$ in a new trial. \n",
    "\n",
    "This particular model uses a random effect for the population mean, and a fixed effect for the treatment effect. There are 3 other models you could fit to represent all possible combinations of fixed or random effects for these two parameters.\n",
    "\n",
    "Build all 4 models to estimate the treatment effect in PyMC3 and \n",
    "\n",
    "1. use convergence diagnostics to check for convergence in each model \n",
    "2. use posterior predictive checks to compare the fit of the models\n",
    "3. use an appropriate metric to compare the models as approximations of the true generating model\n",
    "\n",
    "Which model would you select and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_t_obs = [3, 7, 5, 102, 28, 4, 98, 60, 25, 138, 64, 45, 9, 57, 25, 33, 28, 8, 6, 32, 27, 22]\n",
    "n_t_obs = [38, 114, 69, 1533, 355, 59, 945, 632, 278,1916, 873, 263, 291, 858, 154, 207, 251, 151, 174, 209, 391, 680]\n",
    "r_c_obs = [3, 14, 11, 127, 27, 6, 152, 48, 37, 188, 52, 47, 16, 45, 31, 38, 12, 6, 3, 40, 43, 39]\n",
    "n_c_obs = [39, 116, 93, 1520, 365, 52, 939, 471, 282, 1921, 583, 266, 293, 883, 147, 213, 122, 154, 134, 218, 364, 674]\n",
    "N = len(n_c_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write answer here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": "3",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "84px",
   "left": "1112.66px",
   "right": "20px",
   "top": "120px",
   "width": "187px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
